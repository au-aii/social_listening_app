# app/analyzer.py
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import torch
import logging # ãƒ­ã‚®ãƒ³ã‚°ã‚’è¿½åŠ 

logger = logging.getLogger(__name__)

# ä½¿ç”¨ã™ã‚‹Hugging Faceãƒ¢ãƒ‡ãƒ«å
MODEL_NAME = "Mizuiro-inc/bert-japanese-sentiment-analysis-large"

class SentimentAnalyzer:
    def __init__(self, model_name=MODEL_NAME):
        self.model_name = model_name
        self.sentiment_pipeline = None # åˆæœŸåŒ–ã¯ãƒ¡ã‚½ãƒƒãƒ‰ã§è¡Œã†

        try:
            logger.info(f"Loading tokenizer for {self.model_name}...")
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            
            logger.info(f"Loading model for {self.model_name}...")
            self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name)
            
            # GPUãŒåˆ©ç”¨å¯èƒ½ãªã‚‰GPUã‚’ä½¿ã†è¨­å®š
            self.device = 0 if torch.cuda.is_available() else -1 
            # pipelineã‚’åˆæœŸåŒ–
            self.sentiment_pipeline = pipeline(
                "sentiment-analysis",
                model=self.model,
                tokenizer=self.tokenizer,
                device=self.device,
                # ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ã¯ return_all_scores=True ã‚’è¨­å®šã™ã‚‹ã¨å…¨ãƒ©ãƒ™ãƒ«ã®ã‚¹ã‚³ã‚¢ãŒè¿”ã‚‹
                # koheiduckãƒ¢ãƒ‡ãƒ«ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ€ã‚‚ã‚¹ã‚³ã‚¢ã®é«˜ã„ãƒ©ãƒ™ãƒ«ã®ã¿
            )
            if self.device == 0:
                logger.info(f"Sentiment model '{self.model_name}' loaded successfully on GPU.")
            else:
                logger.info(f"Sentiment model '{self.model_name}' loaded successfully on CPU.")

        except Exception as e:
            logger.error(f"Error loading sentiment model '{self.model_name}': {e}", exc_info=True)
            # sentiment_pipeline ã¯ None ã®ã¾ã¾ã«ãªã‚‹


    def analyze_sentiment(self, text: str):
        if not self.sentiment_pipeline:
            logger.error("Sentiment pipeline is not initialized. Cannot analyze.")
            return {"label": "ERROR", "score": 0.0, "error_message": "Model not loaded"}

        if not text or not isinstance(text, str) or len(text.strip()) == 0:
            logger.warning("Input text for sentiment analysis is empty or invalid.")
            return {"label": "NEUTRAL", "score": 0.0, "note": "Empty or invalid input text"}

        try:
            # ãƒ¢ãƒ‡ãƒ«ãŒå‡¦ç†ã§ãã‚‹æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³é•·ã‚’å–å¾— (ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ512)
            # koheiduck/bert-japanese-finetuned-sentiment ã¯ BERT ãƒ™ãƒ¼ã‚¹ãªã®ã§ 512 ãŒä¸€èˆ¬çš„
            max_len = self.tokenizer.model_max_length if hasattr(self.tokenizer, 'model_max_length') else 512
            
            # truncation=True ã‚’æŒ‡å®šã™ã‚‹ã¨ã€é•·ã™ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆã¯è‡ªå‹•çš„ã«åˆ‡ã‚Šè©°ã‚ã¦ãã‚Œã‚‹
            results = self.sentiment_pipeline(text, truncation=True, max_length=max_len)
            
            # pipelineã®å‡ºåŠ›ã¯é€šå¸¸ãƒªã‚¹ãƒˆ (è¦ç´ æ•°1ã®ã“ã¨ãŒå¤šã„)
            # ä¾‹: [{'label': 'POSITIVE', 'score': 0.99...}]
            if results and isinstance(results, list) and len(results) > 0:
                result = results[0]
                # ãƒ©ãƒ™ãƒ«åã‚’æ—¥æœ¬èªã«ãƒãƒƒãƒ”ãƒ³ã‚° (ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ãƒ©ãƒ™ãƒ«ã«åˆã‚ã›ã¦èª¿æ•´)
                # koheiduck/bert-japanese-finetuned-sentiment ã®å‡ºåŠ›ã¯ 'POSITIVE' or 'NEGATIVE'
                label_map = {
                    "POSITIVE": "ãƒã‚¸ãƒ†ã‚£ãƒ–",
                    "NEGATIVE": "ãƒã‚¬ãƒ†ã‚£ãƒ–",
                    "NEUTRAL": "ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«",
                }
                
                final_label = label_map.get(result["label"].upper(), result["label"]) # å¤§æ–‡å­—ã«å¤‰æ›ã—ã¦æ¤œç´¢
                
                return {
                    "label": final_label,
                    "score": round(result["score"], 4) # ã‚¹ã‚³ã‚¢ã‚’å°æ•°ç‚¹ä»¥ä¸‹4æ¡ã«ä¸¸ã‚ã‚‹
                }
            else:
                logger.warning(f"Unexpected output format from sentiment pipeline for text: {text[:50]}... Output: {results}")
                return {"label": "UNKNOWN", "score": 0.0, "raw_output": results}

        except Exception as e:
            logger.error(f"Error during sentiment analysis for text '{text[:50]}...': {e}", exc_info=True)
            return {"label": "ERROR", "score": 0.0, "error_message": str(e)}

# ãƒ†ã‚¹ãƒˆç”¨ (main.pyã‹ã‚‰å‘¼ã°ã‚Œã‚‹ã®ã§ã€ã“ã“ã§ã®ç›´æ¥å®Ÿè¡Œã¯å¿…é ˆã§ã¯ãªã„)
if __name__ == '__main__':
    # ãƒ­ã‚¬ãƒ¼ã®åŸºæœ¬è¨­å®š (ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚ã®ã¿)
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    analyzer = SentimentAnalyzer()

    if analyzer.sentiment_pipeline:
        test_texts = [
            "ã“ã®æ˜ ç”»ã€æœ¬å½“ã«æ„Ÿå‹•ã—ãŸï¼ç´ æ™´ã‚‰ã—ã„ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã ã£ãŸã€‚", # ãƒã‚¸ãƒ†ã‚£ãƒ–
            "ä»Šæ—¥ã®ãƒ©ãƒ³ãƒã¯æœ€æ‚ªã ã£ãŸã€‚å‘³ãŒã²ã©ã„ã—ã€ã‚µãƒ¼ãƒ“ã‚¹ã‚‚æ‚ªã„ã€‚", # ãƒã‚¬ãƒ†ã‚£ãƒ–
            "ã¾ã‚ã€æ‚ªãã¯ãªã„ã‘ã©ã€æœŸå¾…ã—ã¦ã„ãŸã»ã©ã§ã¯ãªã‹ã£ãŸãªã€‚", # ã‚„ã‚„ãƒã‚¬ãƒ†ã‚£ãƒ–å¯„ã‚Šã‹ã€ãƒ¢ãƒ‡ãƒ«æ¬¡ç¬¬
            "ç‰¹ã«ä½•ã‚‚æ„Ÿã˜ãªã‹ã£ãŸã€‚", # ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«ã«è¿‘ã„ãŒã€ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯2å€¤åˆ†é¡
            "", # ç©ºæ–‡å­—
            "ã“ã‚Œã¯ãƒšãƒ³ã§ã™ã€‚", # æ„Ÿæƒ…ã¨ã¯ç„¡é–¢ä¿‚ãªæ–‡
            "ğŸ˜ŠğŸ‰ğŸ¥³", # çµµæ–‡å­—ã®ã¿ (ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«ä¾å­˜)
            "é•·æ–‡ãƒ†ã‚¹ãƒˆã€‚ã“ã®æ–‡ç« ã¯éå¸¸ã«é•·ãã€ãƒ¢ãƒ‡ãƒ«ã®æœ€å¤§å…¥åŠ›é•·ã‚’è¶…ãˆã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãã®å ´åˆã€é©åˆ‡ã«åˆ‡ã‚Šæ¨ã¦ã‚‰ã‚Œã‚‹ã‹ã€ã‚ã‚‹ã„ã¯ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚BERTãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯é€šå¸¸512ãƒˆãƒ¼ã‚¯ãƒ³ãŒä¸Šé™ã§ã™ãŒã€ã“ã‚Œã¯è¨­å®šã‚„ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…ã«ã‚ˆã£ã¦ç•°ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚é©åˆ‡ãªå‰å‡¦ç†ã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãŒé‡è¦ã§ã™ã€‚ã“ã®ãƒ†ã‚¹ãƒˆæ–‡ã¯ã€ãã®æŒ™å‹•ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã«æ„å›³çš„ã«é•·ãã—ã¦ã„ã¾ã™ã€‚"
        ]

        for text_input in test_texts:
            sentiment = analyzer.analyze_sentiment(text_input)
            print(f"Text: {text_input[:70]}...")
            print(f"Sentiment: {sentiment}\n")
    else:
        print("Sentiment analyzer could not be initialized.")